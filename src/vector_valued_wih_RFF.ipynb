{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-valued function with Random Fourier Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dimension = 2\n",
    "sigma = 2\n",
    "sigma2 = 2*sigma**2\n",
    "\n",
    "# Random Fourier features\n",
    "m = 5 # number of samples\n",
    "w = randn(dimension*m) / sigma # w is the same size as the dimensions times the number of samples\n",
    "b = np.random.rand(m)*2*np.pi # b is the same size as number of samples\n",
    "\n",
    "n = 100 # number of points\n",
    "\n",
    "x1 = randn(n)/2\n",
    "x2 =  randn(n)/2\n",
    "x_vector = np.array([x1, x2])\n",
    "# x_vector = np.block([x1,x2])\n",
    "\n",
    "noise = randn(n) * 2e-1\n",
    "y1 = np.cos(x1) + randn(n) * 1e-1\n",
    "y2 = np.sin(x2) + randn(n) * 1e-1\n",
    "\n",
    "\n",
    "#y1 = 1+np.sin(x1/10) + x1**2\n",
    "#y2 = 0.5 * x2**2 + np.exp(x2)\n",
    "\n",
    "y = np.block([y1, y2])\n",
    "\n",
    "#print(y1, y2)\n",
    "lam = 0.000001 # Regularisaton parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.92733964 ... 0.         0.96414753 0.        ]\n",
      " [0.         1.         0.         ... 0.86692721 0.         0.96414753]\n",
      " [0.92733964 0.         1.         ... 0.         0.86722471 0.        ]\n",
      " ...\n",
      " [0.         0.86692721 0.         ... 1.         0.         0.75432056]\n",
      " [0.96414753 0.         0.86722471 ... 0.         1.         0.        ]\n",
      " [0.         0.96414753 0.         ... 0.75432056 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def k_gauss(x, z):\n",
    "    k = np.exp(-((np.linalg.norm(x-z))**2)/(sigma2))\n",
    "    return k\n",
    "\n",
    "def K_gauss(x, n, dim):\n",
    "    K = np.zeros((dim*n, dim*n))\n",
    "    for i in range(0, n):\n",
    "        for j in range(0, n):\n",
    "            k = k_gauss(x[:,i], x[:,j])\n",
    "            K[i*dim][j*dim] = k\n",
    "            K[i*dim+1][j*dim+1] = k\n",
    "    return K\n",
    "\n",
    "K = K_gauss(x_vector, n, dimension)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a vector with length dim * n\n",
    "def alpha(x, y, lam, n, dim):\n",
    "    K = K_gauss(x, n, dim)\n",
    "    alpha_vector = np.linalg.inv((K + lam*np.eye(dim*n))) @ y\n",
    "    alpha = np.reshape(alpha_vector, (dim, n))\n",
    "    return alpha\n",
    "\n",
    "alpha_ = alpha(x_vector, y, lam, n, dimension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 36135647.90234795,  35722250.07810715,  34920642.65321857,\n",
       "         35933270.83273774,  36097555.31061162,  36098540.70458119,\n",
       "         35982711.58516715,  35533093.57016349,  36075529.49316646,\n",
       "         35855321.02973958,  32405117.15724108,  35668517.36821188,\n",
       "         35735471.23326069,  36098026.10329155,  34281464.56100395,\n",
       "         35615445.98896534,  36137281.06652358,  36056920.44403565,\n",
       "         35547580.19728762,  35322390.656366  ,  35818900.41825636,\n",
       "         35935905.8982366 ,  34273372.84597185,  35704000.14523469,\n",
       "         36133126.21699078,  34779775.74559415,  35960293.29329174,\n",
       "         36049698.41729197,  34033084.66491679,  36111951.2967807 ,\n",
       "         34625515.98406895,  34785496.17132622,  36110416.30578892,\n",
       "         33191406.30985388,  34561445.66570893,  35818714.09424737,\n",
       "         35305309.64522046,  36077782.35879945,  34228842.24395387,\n",
       "         34696345.01533143,  33928304.31475598,  34365930.6183788 ,\n",
       "         33651198.25248374,  35786301.99408776,  35578435.40638535,\n",
       "         36140780.15364705,  36138065.96551668,  35643350.77831171,\n",
       "         35192710.53479817,  36036898.63696702,  35641469.93240397,\n",
       "         34488357.14324614,  35834183.52359028,  35811094.86201805,\n",
       "         35677952.61648262,  36139593.51656964,  35715832.74040046,\n",
       "         36077335.92339451,  36083043.81672473,  34935866.8122276 ,\n",
       "         35961971.87344132,  35954246.85500612,  32580530.43818872,\n",
       "         35982641.90234677,  34900080.37438998,  33758906.82187631,\n",
       "         34344468.5120895 ,  32914425.33599209,  35725975.58389275,\n",
       "         36099174.10636846,  35775479.20704248,  35652073.09228501,\n",
       "         35819489.59473767,  36137963.59087078,  31995331.13318493,\n",
       "         35587771.95416091,  35669611.47361004,  36073590.04121996,\n",
       "         35279732.37214071,  36134158.72938447,  35425882.70059972,\n",
       "         35769582.6667829 ,  36127494.43291447,  33002277.06618438,\n",
       "         36087225.08815176,  36135114.26172314,  36111889.4392394 ,\n",
       "         36129715.39501016,  36038648.19690198,  35712125.08376645,\n",
       "         35316541.05646354,  36140776.68250154,  32626602.89132652,\n",
       "         36139254.02892468,  35932270.07265445,  34188830.31043957,\n",
       "         35547021.93857348,  36016140.19731779,  33822503.48680291,\n",
       "         35054779.80743416],\n",
       "       [-36148025.24266617, -35863072.30728336, -34672960.89529307,\n",
       "        -36031593.12268388, -36140340.43209819, -36047503.94424219,\n",
       "        -36068074.74611388, -35354692.96715634, -36013286.7181795 ,\n",
       "        -35730790.82946048, -31998390.68147866, -35510263.98319351,\n",
       "        -35588325.39149152, -36046709.19025167, -34574170.07277577,\n",
       "        -35448969.74812654, -36118802.52192645, -35987015.89510365,\n",
       "        -35371211.21622584, -35519406.48807542, -35942113.64919316,\n",
       "        -36033580.20714226, -33972241.34648674, -35847898.78112725,\n",
       "        -36108463.21429472, -35032233.19852673, -36051756.17678708,\n",
       "        -36113580.5791358 , -34343352.74437536, -36146177.45246085,\n",
       "        -34351746.03025712, -34525449.85539341, -36066395.56575715,\n",
       "        -32823007.50689857, -34282425.557241  , -35941963.74953458,\n",
       "        -35097902.79807813, -36130250.36618214, -34525388.15576751,\n",
       "        -34956099.78664087, -34245579.95500587, -34652326.1836712 ,\n",
       "        -33308888.1982509 , -35915729.2308607 , -35406484.51515845,\n",
       "        -36131995.66781383, -36121093.38071828, -35797013.36721673,\n",
       "        -35404523.00218948, -36105385.59331086, -35478967.65207684,\n",
       "        -34203504.55457748, -35705347.75163192, -35935824.73660646,\n",
       "        -35826127.13583187, -36126252.48186637, -35857744.63871671,\n",
       "        -36015892.39739154, -36024203.68371972, -35173928.79562267,\n",
       "        -36052991.90195274, -35852494.52502032, -32972347.75781349,\n",
       "        -36068024.68216016, -35141534.76546068, -33423189.70163508,\n",
       "        -34048583.96814784, -33290014.5651838 , -35577198.38599239,\n",
       "        -36048484.52065703, -35635437.63147401, -35491221.53144383,\n",
       "        -35687750.95531316, -36146334.83253013, -32412863.60619176,\n",
       "        -35417183.47854504, -35819128.27705969, -36010501.41765829,\n",
       "        -35069356.42138341, -36148669.02785978, -35610131.38948467,\n",
       "        -35628469.26451039, -36096668.93899762, -32624001.53005362,\n",
       "        -36030374.88458423, -36148285.74699119, -36068828.28037739,\n",
       "        -36149495.81481256, -35962017.38968483, -35561003.23569248,\n",
       "        -35110453.95075445, -36140772.06262925, -33016253.33289698,\n",
       "        -36144709.97691414, -36030837.35317486, -34488251.712496  ,\n",
       "        -35370574.17442335, -35932012.8203441 , -34146636.30652656,\n",
       "        -34820188.13587518]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estiamted_function(alpha, x, n):\n",
    "    function = np.zeros((2, n))\n",
    "    for i in range(n):\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "        for j in range(n):\n",
    "            k = k_gauss(x[:, i], x[:, j])\n",
    "            sum1 = sum1 + k * alpha[0, j]\n",
    "            sum2 = sum2 + k * alpha[1, j]\n",
    "        function[0, i] = sum1\n",
    "        function[1, i] = sum2\n",
    "    return function\n",
    "\n",
    "estiamted_function(alpha_, x_vector, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "141ff6ceaf6cd9d5f09b7c3dc742baf39b1c18dfc3a488d16317bf0a7860a04c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
